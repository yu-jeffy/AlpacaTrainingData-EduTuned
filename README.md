# AlpacaTrainingData-EduTuned
Stanford Alpaca LLM Cleaned Training Data, appended with prompts and training data from other training sets and educational sources

Training data used/sampled (not exhaustive list):

https://github.com/tatsu-lab/stanford_alpaca

https://github.com/gururise/AlpacaDataCleaned

https://github.com/Instruction-Tuning-with-GPT-4

https://github.com/teknium1/GPTeacher

https://github.com/XueFuzhao/InstructionWild

https://github.com/zhilizju/Awesome-instruction-tuning

https://github.com/yaodongC/awesome-instruction-dataset

https://huggingface.co/datasets/JosephusCheung/GuanacoDataset

https://github.com/google-research/FLAN

https://github.com/anthropics/hh-rlhf

https://github.com/PhoebusSi/Alpaca-CoT


raw data, not tokenized
